# -*- coding: utf-8 -*-
"""t20_scheduler_full.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oUZua6wPQUviobj9Bag2cFeq5GOH9bom
"""

# Full integrated script: ML-driven tournament scheduling & simulation
# No input() anywhere â€” fully programmatic.
# Update file paths below if needed before running.

import math
from math import radians, sin, cos, sqrt, atan2
import pandas as pd
import folium
from sklearn.cluster import KMeans
import itertools
from scipy.optimize import linear_sum_assignment
import numpy as np
from itertools import permutations, combinations
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# -----------------------------
# Config / Paths (edit if needed)
# -----------------------------
RANDOM_SEED = 42
n_top = 2  # top N teams from each group (fixed, no input)

dataset_paths = {
    "Group_1": "/content/drive/MyDrive/IPL optimization/Group_A_teams.csv",
    "Group_2": "/content/drive/MyDrive/IPL optimization/Group_B_teams.csv"
}

venues_path = "/content/drive/MyDrive/IPL optimization/t20_world_cup_2024_venues.csv"

historical_matches_path = "/content/drive/MyDrive/IPL optimization/2022_Teams_played.csv"

# -----------------------------
# Load Data
# -----------------------------
# Load group datasets programmatically
datasets = {name: pd.read_csv(path) for name, path in dataset_paths.items()}

# Load venues (if present)
try:
    venues_df = pd.read_csv(venues_path)
except Exception as e:
    print("Warning: could not load venues CSV:", e)
    venues_df = None

# Load historical matches for ML model
df = pd.read_csv(historical_matches_path)
print("Historical matches shape:", df.shape)
print(df.head())

# -----------------------------
# Preprocess historical matches
# -----------------------------
df = df[df['Winner'].notna()]
df = df[df['Winner'].str.lower() != 'no result']
df = df.dropna(subset=['Team 1', 'Team 2', 'Winner', 'Match Date'])
df['Team 1'] = df['Team 1'].str.strip()
df['Team 2'] = df['Team 2'].str.strip()
df['Winner'] = df['Winner'].str.strip()

def maybe_int(x):
    try:
        return int(x)
    except:
        return np.nan

if 'First Innings Score' in df.columns:
    df['First Innings Score'] = df['First Innings Score'].apply(maybe_int)
else:
    df['First Innings Score'] = np.nan

if 'Second Innings Score' in df.columns:
    df['Second Innings Score'] = df['Second Innings Score'].apply(maybe_int)
else:
    df['Second Innings Score'] = np.nan

# Keep only matches where Winner equals one of the playing teams (defensive)
df = df[df['Winner'].isin(df['Team 1'].unique()) | df['Winner'].isin(df['Team 2'].unique())]

df['Match Date'] = pd.to_datetime(df['Match Date'], dayfirst=True, errors='coerce')
df = df.sort_values('Match Date').reset_index(drop=True)

# -----------------------------
# Team encoding (based on historical data)
# -----------------------------
teams = sorted(list(set(df["Team 1"]).union(set(df["Team 2"]))))
team_to_index = {team: i for i, team in enumerate(teams)}

def one_hot_team(team_name):
    """Returns one-hot vector for team_name; if unknown, returns all-zero vector."""
    vec = np.zeros(len(teams))
    idx = team_to_index.get(team_name)
    if idx is not None:
        vec[idx] = 1
    return vec

# Encode Team1 & Team2 into vectors (training set)
team1_encoded = np.vstack(df['Team 1'].apply(one_hot_team))
team2_encoded = np.vstack(df['Team 2'].apply(one_hot_team))

# Numeric features (fill NaNs with 0)
numeric_features = df[['First Innings Score', 'Second Innings Score']].fillna(0).values

# Final X and y
X = np.hstack([team1_encoded, team2_encoded, numeric_features])
y = (df['Winner'] == df['Team 1']).astype(int).values

print("X shape:", X.shape)
print("y shape:", y.shape)

# -----------------------------
# Train/test split & model
# -----------------------------
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
model = RandomForestClassifier(n_estimators=300, random_state=RANDOM_SEED)
model.fit(X_train, y_train)
print("Model training complete.")

# -----------------------------
# Helper: Haversine distance
# -----------------------------
def haversine(lat1, lon1, lat2, lon2):
    R = 6371  # km
    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
    c = 2 * atan2(sqrt(a), sqrt(1 - a))
    return R * c

# -----------------------------
# Venue TSP helpers
# -----------------------------
def venue_finder(venues):
    """Brute-force TSP for small n (venues: list of (Name, Lat, Lon)). Returns (best_paths, min_distance)."""
    if not venues:
        return [], 0
    best_paths = []
    min_distance = float('inf')
    for perm in permutations(venues):
        total_dist = 0.0
        for i in range(len(perm) - 1):
            v1, v2 = perm[i], perm[i + 1]
            total_dist += haversine(v1[1], v1[2], v2[1], v2[2])
        if total_dist < min_distance:
            min_distance = total_dist
            best_paths = [perm]
        elif abs(total_dist - min_distance) < 1e-9:
            best_paths.append(perm)
    return best_paths, min_distance

def venue_finder_with_start(venues, start_venue):
    """Find best permutations that start with start_venue."""
    if not venues:
        return [], 0
    best_paths = []
    min_distance = float('inf')
    for perm in permutations(venues):
        if perm[0][0] != start_venue:
            continue
        total_dist = 0.0
        for i in range(len(perm) - 1):
            v1, v2 = perm[i], perm[i + 1]
            total_dist += haversine(v1[1], v1[2], v2[1], v2[2])
        if total_dist < min_distance:
            min_distance = total_dist
            best_paths = [perm]
        elif abs(total_dist - min_distance) < 1e-9:
            best_paths.append(perm)
    return best_paths, min_distance

# -----------------------------
# Scheduler (round-robin-ish)
# -----------------------------
def generate_fair_schedule(teams_list, best_path):
    """
    teams_list: list of team names
    best_path: list-like of (VenueName, Lat, Lon) or [(name,lat,lon),...]
    Returns: schedule (list of rounds; each round is list of (match, venue)),
             xtra (list of extra teams per round), venue_usage (counts)
    """
    venues = [venue[0] for venue in best_path]
    matches = list(combinations(teams_list, 2))
    total_matches = len(matches)
    num_venues = len(venues)
    if num_venues == 0:
        return [], [], []
    avg_matches = total_matches // num_venues
    remainder = total_matches % num_venues
    venue_match_counts = [avg_matches + (1 if i < remainder else 0) for i in range(num_venues)]

    schedule, xtra = [], []
    extra_index, venue_index = 0, 0
    venue_usage = [0] * num_venues

    matches_copy = matches[:]
    while matches_copy:
        round_matches = []
        round_teams = set()
        extra_team = None

        for match in matches_copy[:]:
            t1, t2 = match
            if t1 not in round_teams and t2 not in round_teams:
                while venue_index < num_venues and venue_usage[venue_index] >= venue_match_counts[venue_index]:
                    venue_index += 1
                if venue_index >= num_venues:
                    venue_index = num_venues - 1
                round_matches.append((match, venues[venue_index]))
                venue_usage[venue_index] += 1
                round_teams.update([t1, t2])
                matches_copy.remove(match)

        leftover_teams = [t for t in teams_list if t not in round_teams]
        if leftover_teams:
            extra_team = leftover_teams[extra_index % len(leftover_teams)]
            extra_index += 1
            for t in round_teams:
                candidate = (extra_team, t) if (extra_team, t) in matches_copy else (t, extra_team)
                if candidate in matches_copy:
                    while venue_index < num_venues and venue_usage[venue_index] >= venue_match_counts[venue_index]:
                        venue_index += 1
                    if venue_index >= num_venues:
                        venue_index = num_venues - 1
                    round_matches.append((candidate, venues[venue_index]))
                    venue_usage[venue_index] += 1
                    matches_copy.remove(candidate)
                    break

        schedule.append(round_matches)
        xtra.append(extra_team)

    return schedule, xtra, venue_usage

# -----------------------------
# Prediction wrapper
# -----------------------------
def predict_match(teamA, teamB, first_score=0, second_score=0):
    t1 = one_hot_team(teamA)
    t2 = one_hot_team(teamB)
    x_input = np.hstack([t1, t2, [first_score, second_score]]).reshape(1, -1)
    pred = model.predict(x_input)[0]
    return teamA if pred == 1 else teamB

# -----------------------------
# Simulation functions
# -----------------------------
def simulate_results(teams_list, schedule):
    points_table = {team: {"Played": 0, "Won": 0, "Lost": 0, "Points": 0} for team in teams_list}
    results_log = []

    for rnd, round_matches in enumerate(schedule, start=1):
        for match, venue in round_matches:
            t1, t2 = match
            winner = predict_match(t1, t2)
            loser = t2 if winner == t1 else t1

            points_table[t1]["Played"] += 1
            points_table[t2]["Played"] += 1
            points_table[winner]["Won"] += 1
            points_table[loser]["Lost"] += 1
            points_table[winner]["Points"] += 2

            results_log.append({
                "Round": rnd,
                "Match": f"{t1} vs {t2}",
                "Venue": venue,
                "Winner": winner
            })

    results_df = pd.DataFrame(results_log)
    points_df = pd.DataFrame.from_dict(points_table, orient="index").reset_index()
    points_df.rename(columns={"index": "Team"}, inplace=True)
    points_df = points_df.sort_values(by=["Points", "Won"], ascending=[False, False]).reset_index(drop=True)
    return results_df, points_df

def simulate_knockout(teams_list, venues_list):
    teams_copy = teams_list[:]
    np.random.seed(RANDOM_SEED)
    np.random.shuffle(teams_copy)
    knockout_log = []
    round_num = 1
    venue_idx = 0

    while len(teams_copy) > 1:
        next_round = []

        if len(teams_copy) % 2 == 1:
            bye_team = teams_copy.pop()
            next_round.append(bye_team)
            knockout_log.append({
                "Round": round_num,
                "Match": f"{bye_team} (bye)",
                "Venue": None,
                "Winner": bye_team
            })

        for i in range(0, len(teams_copy), 2):
            t1 = teams_copy[i]
            t2 = teams_copy[i + 1]
            venue = venues_list[venue_idx % len(venues_list)][0] if venues_list else None
            venue_idx += 1

            winner = predict_match(t1, t2)
            next_round.append(winner)
            knockout_log.append({
                "Round": round_num,
                "Match": f"{t1} vs {t2}",
                "Venue": venue,
                "Winner": winner
            })

        teams_copy = next_round
        round_num += 1

    champion = teams_copy[0] if teams_copy else None
    knockout_df = pd.DataFrame(knockout_log)
    return knockout_df, champion

# -----------------------------
# MAIN: pipeline using programmatic datasets & venues
# -----------------------------
print("\n========= TOURNAMENT PIPELINE (PROGRAMMATIC) =========\n")
print("Loaded group datasets:")
for group_name, gdf in datasets.items():
    print(f" - {group_name}: {len(gdf)} rows, columns: {list(gdf.columns)[:6]}")

if venues_df is not None:
    print(f"Loaded venues: {len(venues_df)} rows, columns: {list(venues_df.columns)[:6]}")
else:
    print("No venues loaded.")

# -----------------------------
# Optional: KMeans clustering of venues (if venues_df present)
# -----------------------------
clusters = {}
if venues_df is not None and len(datasets) > 0:
    total_teams = sum(len(df_) for df_ in datasets.values())
    num_venues = len(venues_df)
    ratio = num_venues / total_teams if total_teams > 0 else 0
    if ratio < 1:
        print("Skipping KMeans clustering (venues/teams < 1).")
    else:
        value = int(ratio)
        k = max(1, value + 1)
        print(f"Running KMeans with k = {k}")
        coords = venues_df[["Latitude", "Longitude"]]
        kmeans = KMeans(n_clusters=k, random_state=RANDOM_SEED, n_init=10)
        venues_df["Cluster"] = kmeans.fit_predict(coords)
        for i in range(k):
            clusters[f"Cluster_{i+1}"] = venues_df[venues_df["Cluster"] == i].reset_index(drop=True)

# -----------------------------
# Compute cost matrix (group -> cluster) using nearest-venue distance sum
# -----------------------------
results = {}
cost_matrix = []
group_names = list(datasets.keys())
cluster_names = list(clusters.keys())

for group_name, group_df in datasets.items():
    row = []
    results[group_name] = {}
    for cluster_name, cluster_df in clusters.items():
        total_distance = 0.0
        for _, team in group_df.iterrows():
            if "Latitude" not in team or "Longitude" not in team:
                # skip if team row doesn't contain lat/lon
                continue
            dists = [
                haversine(team["Latitude"], team["Longitude"],
                          venue["Latitude"], venue["Longitude"])
                for _, venue in cluster_df.iterrows()
            ]
            if dists:
                total_distance += min(dists)
        results[group_name][cluster_name] = total_distance
        row.append(total_distance)
    if row:
        cost_matrix.append(row)

assignments = {}
if cost_matrix:
    cost_matrix = np.array(cost_matrix)
    row_ind, col_ind = linear_sum_assignment(cost_matrix)
    for i, j in zip(row_ind, col_ind):
        assignments[group_names[i]] = cluster_names[j]
    print("\nOptimal assignments (group->cluster):", assignments)
else:
    print("\nNo cost matrix computed (skipping assignment).")

# -----------------------------
# For each assigned cluster: find best path, schedule and simulate
# -----------------------------
all_qualified = []
qualified_teams = {}

for group_name, cluster_name in assignments.items():
    cluster_df = clusters[cluster_name].reset_index(drop=True)
    venues_list = list(zip(cluster_df["Venue"], cluster_df["Latitude"], cluster_df["Longitude"]))
    n = len(cluster_df)
    print(f"\nGroup {group_name} assigned to {cluster_name} with {n} venues.")

    if n <= 9 and n > 0:
        best_paths, best_dist = venue_finder(venues_list)
    elif n > 0:
        # Nearest neighbor heuristic
        unvisited = set(range(n))
        current, order, total_dist = 0, [0], 0.0
        unvisited.remove(0)
        while unvisited:
            next_city = min(unvisited, key=lambda j: haversine(
                cluster_df.iloc[current]["Latitude"], cluster_df.iloc[current]["Longitude"],
                cluster_df.iloc[j]["Latitude"], cluster_df.iloc[j]["Longitude"]))
            total_dist += haversine(cluster_df.iloc[current]["Latitude"], cluster_df.iloc[current]["Longitude"],
                                    cluster_df.iloc[next_city]["Latitude"], cluster_df.iloc[next_city]["Longitude"])
            current = next_city
            order.append(current)
            unvisited.remove(current)
        best_paths, best_dist = [[tuple(cluster_df.iloc[i][["Venue", "Latitude", "Longitude"]]) for i in order]], total_dist
    else:
        best_paths, best_dist = [], 0

    if best_paths:
        print("Best path (venue order):", [v[0] for v in best_paths[0]])
        print(f"Path distance: {best_dist:.2f} km")
    else:
        print("No best path computed (no venues).")

    # Try one fixed start (optional)
    for start in cluster_df["Venue"].tolist()[:1]:
        paths, dist = venue_finder_with_start(venues_list, start)
        print(f"Best paths starting from {start}:")
        for p in paths:
            print([v[0] for v in p], f" dist={dist:.2f} km")
        break

    # Build teams list from group dataframe
    group_df = datasets[group_name]
    team_col = None
    for candidate in ["Country", "Team", "Team Name", "Team_Name", "team", "Name"]:
        if candidate in group_df.columns:
            team_col = candidate
            break
    if team_col is None:
        team_col = group_df.columns[0]  # fallback

    teams_list = group_df[team_col].tolist()

    if best_paths:
        schedule, xtra, venue_usage = generate_fair_schedule(teams_list, best_paths[0])
    else:
        if venues_list:
            schedule, xtra, venue_usage = generate_fair_schedule(teams_list, venues_list)
        else:
            schedule, xtra, venue_usage = [], [], []

    print("\nSchedule (first 5 rounds):")
    for i, round_matches in enumerate(schedule[:5], start=1):
        print(f"Round {i}:")
        for match, venue in round_matches:
            print(f"  {match[0]} vs {match[1]} @ {venue}")

    if schedule:
        results_df, points_df = simulate_results(teams_list, schedule)
        print("\nMatch results (sample):")
        print(results_df.head())
        print("\nPoints table:")
        print(points_df)
    else:
        print("No schedule for simulation for this group.")

    # Decide top-n from points table (if available) else fallback
    if 'points_df' in locals() and not points_df.empty:
        top_n = points_df.head(n_top)["Team"].tolist()
    else:
        top_n = teams_list[:n_top] if teams_list else []

    qualified_teams[group_name] = top_n
    all_qualified.extend(top_n)

# If there were no cluster assignments, fallback: compute schedule using all venues and each dataset
if not assignments:
    for group_name, group_df in datasets.items():
        team_col = None
        for candidate in ["Country", "Team", "Team Name", "Team_Name", "team", "Name"]:
            if candidate in group_df.columns:
                team_col = candidate
                break
        if team_col is None:
            team_col = group_df.columns[0]
        teams_list = group_df[team_col].tolist()
        if venues_df is not None:
            used_venues = list(zip(venues_df["Venue"], venues_df["Latitude"], venues_df["Longitude"]))
            used_venues = used_venues[:max(1, min(len(used_venues), len(teams_list)))]
        else:
            used_venues = []
        if used_venues:
            schedule, _, _ = generate_fair_schedule(teams_list, used_venues)
            results_df, points_df = simulate_results(teams_list, schedule)
        else:
            results_df, points_df = pd.DataFrame(), pd.DataFrame()
        if not points_df.empty:
            top_n = points_df.head(n_top)["Team"].tolist()
        else:
            top_n = teams_list[:n_top] if teams_list else []
        qualified_teams[group_name] = top_n
        all_qualified.extend(top_n)

print("\nQualified teams by group:")
for g, teams_out in qualified_teams.items():
    print(g, teams_out)

print("\nAll qualified teams for knockout:", all_qualified)

# -----------------------------
# Knockout stage
# -----------------------------
if venues_df is not None:
    venues_list_full = list(zip(venues_df["Venue"], venues_df["Latitude"], venues_df["Longitude"]))
else:
    venues_list_full = []

if all_qualified:
    knockout_df, champion = simulate_knockout(all_qualified, venues_list_full)
    print("\nKnockout results:")
    print(knockout_df)
    print("\nChampion:", champion)
else:
    print("No qualified teams for knockout stage.")